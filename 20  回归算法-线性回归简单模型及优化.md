接下来的将会是迭代算法，也就是准确率可以提高、误差可以减小的算法。

**迭代算法**：算法+策略+优化(对于线性回归算法来说就是：线性回归算法+损失函数+正规方程或梯度下降)

# 损失函数(误差大小)

`yi`为第i个训练样本的真实值

`hw(xi)`为第i个训练样本特征值组合预测函数

总损失定义(**最小二乘法**)：`J(θ)=(hw(x1)-y1)²+(hw(x2)-y2)²+...+(hw(xm)-ym)²=Σ[i=1~m](hw(xi)-yi)²`

**我们要找到最小的损失函数，即为找到能使误差最小的权重值**

# 最小二乘法两种方法原理

## 正规方程

 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta%3D%28X%5ETX%29%5E%7B-1%7DX%5ETy%5C%5C) 

这里θ代表权重，X为特征值矩阵，y为目标值矩阵

缺点：当特征过于复杂，求解速度太慢

## 梯度下降

以单变量中的`w0`,`w1`为例子：

`w1=-w1-α[∂cost(w0+w1x1)]/[∂w1]`

`w0=-w0-α[∂cost(w0+w1x1)]/[∂w1]`

α为学习速率，需要手动指定，`[∂cost(w0+w1x1)]/[∂w1]`表示方向

理解：沿着这个函数下降的方向找到山谷的最低点，然后更新w值

# `sklearn`最简单线性回归模型、梯度下降优化模型`API`

## 最简单线性回归模型

`sklearn.linear_model.LinearRegression`

## 梯度下降

`sklearn.linear_model.SGDRegressor`

