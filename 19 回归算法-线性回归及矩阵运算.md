与之前的分类算法不同的是，回归算法的目标值是连续的

# 使用`Matplotlib`画出散点图

**代码**：

```python
# 导入matplotlib模块画散点图的模块
import matplotlib.pyplot as pit
# 指定画板大小
pit.figure(figsize=(10, 10))
# 输入数据
pit.scatter([60, 72, 75, 80, 83], [126, 151.2, 157.5, 168, 174.3])
# 显示散点图
pit.show()
```

# 线性关系模型

一个通过属性的线性组合来进行预测的函数：

`f(x)=w1x1+w2x2+...+wdxd+b`

w为权重，b为偏置项，可以理解为`w0*1`

# 线性回归

**定义**：线性回归通过一个或多个自变量与因变量之间进行建模的回归分析。其中可以为一个或多个自变量之间的线性组合(线性回归的一种)

**一元线性回归**：涉及到的变量只有一个

**多元线性回归**：涉及到的变量两个或两个以上

通用公式：`h(w)=w0+w1x1+w2x2+...=wTx`

其中w,x为矩阵：`w=(w0       ,  x=(1`

​                                   `w1             x1`

​                                   `w2)            x2)`

# 数组与矩阵

## 数组

0维：单个数字，如5

1维：列表，如[5,2,3,16]

2维：多个样本，如[[3,2,5,6],[3,8,4,9]]

3维：多张表，如[

[[3,2,5,6],[3,8,4,9]],

[[1,5,8,7],[2,6,3,9]]

]

数组的运算：加法、乘法

处理数组的`API`:`numpy`，数组的形式：`ndarray`

## 矩阵

m行l列的矩阵与l行n列的矩阵相乘得到m行n列的矩阵

**代码分析**：

```python
import numpy as np
a = [[1, 3, 6, 8], [7, 4, 2, 5], [6, 5, 2, 9]]
b1 = [[2], [2], [2], [2]]
b2 = [2, 2, 2, 2]
print('数组相乘:', '\n', np.multiply(a, b2))
print('矩阵相乘:', '\n', np.dot(a, b1))
```

**结果分析**：

```python
数组相乘: 
 [[ 2  6 12 16]
 [14  8  4 10]
 [12 10  4 18]]
矩阵相乘: 
 [[36]
 [36]
 [44]]
```

