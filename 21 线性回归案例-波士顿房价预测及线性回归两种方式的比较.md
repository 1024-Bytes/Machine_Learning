# 波士顿房价数据案例分析流程

1.波士顿地区房价数据获取

2.波士顿地区房价数据分割

3.训练与测试数据集标准化处理

4.使用最简单的线性回归模`LinearRegression`和梯度下降估计`SGDRegressor`对房价进行预测

# 案例实践

**代码**：

```python
# 线性回归梯度下降API
from sklearn.linear_model import SGDRegressor
# 普通线性回归（正规方程）API
from sklearn.linear_model import LinearRegression
# 加载波士顿房价数据集
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
def mylinear():
    """
    线性回归直接预测房价
    :return: None
    """
    # 获取数据
    lb = load_boston()
    # 分割数据集
    x_train, x_test, y_train,y_test = train_test_split(lb.data, lb.target, test_size=0.25)
    # 进行标准化处理
    # 特征值与目标值都需要进行标准化处理
    std_x = StandardScaler()
    x_train = std_x.fit_transform(x_train)
    x_test = std_x.transform(x_test)
    std_y = StandardScaler()
    y_train = std_y.fit_transform(y_train.reshape(-1,1))
    """标准化处理注意转化数据集的形状，其要求必须是二维数组
    Reshape your data either using array.reshape(-1, 1) if your data has a single feature 
    or array.reshape(1, -1) if it contains a single sample."""
    y_test = std_y.transform(y_test.reshape(-1,1))
     print(std_y.inverse_transform(y_test))
    # 估计器进行预测
    # 正规方程求权重进行预测
    lr = LinearRegression()
    lr.fit(x_train, y_train)
    print("训练得到的参数：", '\n', lr.coef_)
    y_lr_predict = std_y.inverse_transform(lr.predict(x_test))
    "inverse_transform可以将y_predict还原为标准化前的结果"
    print("测试集预测房价结果：", '\n', y_lr_predict)
    # 梯度下降求权重进行预测
    sgd = SGDRegressor()
    sgd.fit(x_train, y_train)
    print("训练得到的参数：", '\n', sgd.coef_)
    y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test))
    "inverse_transform可以将y_predict还原为标准化前的结果"
    print("测试集预测房价结果：", '\n', y_sgd_predict)

    return None


if __name__ == "__main__":
    mylinear()
```

**运行结果**：

```python
[[30.1]
 [19.6]
 [20.3]
 [14.5]
 [ 7.2]
 [42.8]
 [21.7]
 [21.9]
 [35.4]
 [20.3]
 [20.6]
 [50. ]
 [21.8]
 [23.1]
 [14.5]
 [25. ]
 [33. ]
 [15.6]
 [15.6]
 [31.2]
 [19.8]
 [22.1]
 [28.6]
 [17.9]
 [19.1]
 [24.1]
 [15.4]
 [48.3]
 [12.7]
 [14.9]
 [28. ]
 [25. ]
 [20.1]
 [17.7]
 [22. ]
 [44.8]
 [22.2]
 [22.2]
 [28.4]
 [32.2]
 [10.2]
 [24.3]
 [ 8.8]
 [32.7]
 [33.1]
 [24.8]
 [26.7]
 [19.3]
 [28.7]
 [22.7]
 [20.4]
 [37. ]
 [22.9]
 [43.5]
 [20.5]
 [23.7]
 [21.9]
 [50. ]
 [18.2]
 [16.8]
 [19.3]
 [19.3]
 [23.8]
 [18.7]
 [18.4]
 [29. ]
 [22.6]
 [13.2]
 [31.5]
 [25. ]
 [19.1]
 [ 9.6]
 [14.9]
 [14.4]
 [20.4]
 [23.5]
 [37.2]
 [16.1]
 [41.7]
 [24. ]
 [16.4]
 [14.4]
 [22.8]
 [ 8.3]
 [21.7]
 [23.4]
 [20.9]
 [30.5]
 [42.3]
 [24.4]
 [44. ]
 [26.2]
 [23.8]
 [13.1]
 [35.4]
 [19.1]
 [19.2]
 [26.4]
 [50. ]
 [23.2]
 [21.1]
 [28.7]
 [21.7]
 [10.9]
 [21.4]
 [16.3]
 [ 7.4]
 [28.4]
 [21.9]
 [19.6]
 [14.6]
 [50. ]
 [23.1]
 [13.1]
 [25.3]
 [23.9]
 [22.9]
 [23. ]
 [17.5]
 [19.4]
 [ 9.5]
 [20.6]
 [22.9]
 [28.2]
 [27.1]
 [20.6]
 [24.8]]
训练得到的参数： 
 [[-0.1168493   0.13065111 -0.01809135  0.1001269  -0.21625476  0.24219338
   0.00632522 -0.38481299  0.34252033 -0.2339472  -0.20122309  0.10455208
  -0.47173201]]
测试集预测房价结果： 
 [[35.15282957]
 [21.13113293]
 [22.2784361 ]
 [13.49090346]
 [17.99122218]
 [28.38203653]
 [24.55282579]
 [17.14700467]
 [30.49625383]
 [18.11842979]
 [16.53391812]
 [36.27660861]
 [21.21744187]
 [16.90419347]
 [18.1139513 ]
 [29.14495412]
 [22.05464414]
 [15.52068557]
 [12.9267883 ]
 [28.34600026]
 [18.02931671]
 [27.42978293]
 [27.34361738]
 [ 1.23513401]
 [23.77309143]
 [19.56660036]
 [14.11282571]
 [36.61194661]
 [18.6825235 ]
 [18.06632564]
 [28.34389908]
 [27.10114941]
 [23.14678792]
 [20.76310197]
 [21.37598854]
 [37.97659661]
 [18.97638593]
 [26.13111115]
 [31.24609322]
 [30.52050924]
 [ 6.62829963]
 [24.62973319]
 [ 5.04935024]
 [29.2765049 ]
 [35.87378767]
 [26.10673944]
 [34.21388794]
 [17.39215894]
 [27.82265391]
 [24.26513196]
 [21.14708519]
 [30.08924087]
 [25.15870207]
 [39.0908621 ]
 [19.23250272]
 [28.05544239]
 [38.61603556]
 [40.93291733]
 [19.48405092]
 [22.39345255]
 [20.6315156 ]
 [20.95922286]
 [25.33287827]
 [21.77606588]
 [19.32102101]
 [32.77537998]
 [27.26338871]
 [ 7.60251368]
 [32.53088676]
 [24.38179182]
 [19.98760536]
 [14.39831628]
 [14.87630527]
 [ 7.32654038]
 [19.93634493]
 [30.32683756]
 [33.19578117]
 [21.9166022 ]
 [37.53021364]
 [25.41374785]
 [19.14445553]
 [ 3.00673769]
 [28.90181602]
 [13.57388075]
 [24.26533673]
 [23.6526185 ]
 [20.52701915]
 [29.80230048]
 [36.28715551]
 [23.26726863]
 [36.96547688]
 [23.43792132]
 [22.42233261]
 [15.56116196]
 [33.86819009]
 [17.09645424]
 [23.97735442]
 [28.43337542]
 [39.88113196]
 [25.75518972]
 [20.73467156]
 [25.19867514]
 [22.90739367]
 [13.93154977]
 [22.516074  ]
 [12.18321449]
 [ 5.48809989]
 [28.69127143]
 [23.19672523]
 [17.76972853]
 [ 7.61469776]
 [42.60205243]
 [24.76779009]
 [20.73005202]
 [24.9332739 ]
 [27.96346815]
 [28.7390331 ]
 [20.00693982]
 [15.71552998]
 [22.78603833]
 [12.54493105]
 [20.01251364]
 [22.28561605]
 [33.22630412]
 [26.25767651]
 [22.13567357]
 [24.88034534]]
D:\PycharmProjects\Machines_learning_test\venv\lib\site-packages\sklearn\utils\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
训练得到的参数： 
 [-0.09810594  0.08974598 -0.0654939   0.11403258 -0.1541405   0.26760605
 -0.00278315 -0.3302572   0.19443956 -0.08429606 -0.18626088  0.10931679
 -0.45894721]
测试集预测房价结果： 
 [34.62971065 20.70051993 22.43074324 13.87976202 18.11538255 29.62125468
 25.51174941 16.64053892 29.76428359 17.77567624 17.26538683 36.28118247
 21.5332126  17.4736059  18.49585064 27.82151882 22.84324657 15.97410369
 13.38754685 28.85719523 18.13158128 27.21491393 27.13627304  0.4632283
 23.49057308 21.20467916 14.9847906  36.65506859 18.6357561  18.30872943
 28.21922459 26.9202818  22.67731883 20.96034265 19.67789092 37.81118681
 19.24175237 25.77701682 29.8714148  30.24898918  6.45678243 24.03616755
  6.05372351 30.06030377 35.63107974 25.8660269  34.19882974 17.37281036
 27.19960426 25.20846078 21.4372046  30.68437708 24.83922357 38.71598719
 19.46511708 27.71300995 39.85153418 41.57761928 19.93075281 23.02608927
 21.05525508 22.32340637 25.44221549 21.52873593 19.91928623 32.90022165
 27.38077499  8.12711454 32.41175596 24.06502695 19.77609622 14.70605466
 15.16229193  7.1938681  20.43520062 29.71118532 32.68977589 21.33417903
 37.62378982 24.86748414 19.44182801  3.35280187 28.90482268 13.60975648
 24.21742725 23.62894523 20.99420204 30.29660999 36.44489048 23.09351998
 35.78867336 23.91450473 22.13681363 15.80288014 33.09285622 16.91972306
 24.40838504 27.90233796 39.70226008 25.66462503 20.84340019 25.4462634
 23.00080392 14.27371686 22.22360367 11.64627062  5.57174869 28.83065423
 23.39153378 18.11882724  8.38659749 41.03703245 24.93187416 20.77117349
 24.86898816 28.17602415 27.45155366 20.62006225 17.2362468  23.11258895
 12.52772721 19.77095378 22.31673859 31.8271797  25.96243702 21.76074167
 25.12835091]
```

# 回归性能评估

**均方误差评价机制**：

`MSE=1/m*Σ[i=1~m](yi-y)`

注：yi为预测值，y为真实值

**`API`及语法**

`mean_squared_error(y_true, y_predict)`

均方误差求回归损失

y_true:真实值

y_predict:预测值

return：浮点数结果

注：真实值和预测值为标准化之前的值

**代码**：

```python
# 导入均方误差API
from sklearn.metrics import mean_squared_error
 # 均方误差机制评估回归性能
    print("正规方程误差：", mean_squared_error(std_y.inverse_transform(y_test), y_lr_predict))
    print("梯度下降误差：", mean_squared_error(std_y.inverse_transform(y_test), y_sgd_predict))
```

**运行结果**：

```python
正规方程误差： 24.928928990383422
梯度下降误差： 25.206777229149953
```

#  正规方程和梯度下降的比较

| 梯度下降                  | 正规方程                                                   |
| ------------------------- | ---------------------------------------------------------- |
| 需要选择学习率α           | 不需要                                                     |
| 需要多次迭代              | 一次运算得出                                               |
| 当特征数量n大时能较好使用 | 特征数量n较大时则计算的时间复杂度较高，n尽量不要大于100000 |
| 适用于各种类型的模型      | 只适用于线性模型，不适合逻辑回归模型等其他模型             |

正规方程不能解决拟合问题

