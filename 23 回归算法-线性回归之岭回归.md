# `Ridge之API`

`sklearn.linear_model.Ridge(alpha=1.0)`

具有l2正则化的线性最小二乘法

`alpha`:正则化力度，正则化力度越大，模型越简单(正则化的大小可以是0~1之间的小数，也可以是1~10之间的整数)

`coef_`:回归系数

# 岭回归预测房价应用案例

**代码**：

```python
# 带有正则化的线性回归（岭回归）API
from sklearn.linear_model import Ridge
# 加载波士顿房价数据集
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# 导入均方误差API
from sklearn.metrics import mean_squared_error
def mylinear():
    """
    岭回归预测房价
    :return: None
    """
    # 获取数据
    lb = load_boston()
    # 分割数据集
    x_train, x_test, y_train,y_test = train_test_split(lb.data, lb.target, test_size=0.25)
    # 进行标准化处理
    # 特征值与目标值都需要进行标准化处理
    std_x = StandardScaler()
    x_train = std_x.fit_transform(x_train)
    x_test = std_x.transform(x_test)
    std_y = StandardScaler()
    y_train = std_y.fit_transform(y_train.reshape(-1,1))
    """标准化处理注意转化数据集的形状，其要求必须是二维数组
    Reshape your data either using array.reshape(-1, 1) if your data has a single feature 
    or array.reshape(1, -1) if it contains a single sample."""
    y_test = std_y.transform(y_test.reshape(-1,1))
    print(std_y.inverse_transform(y_test))
    # 估计器进行预测
    # 岭回归求权重进行预测
    rd = Ridge(alpha=1.0)
    rd.fit(x_train, y_train)
    print("训练得到的参数：", '\n', rd.coef_)
    y_predict = std_y.inverse_transform(rd.predict(x_test))
    "inverse_transform可以将y_predict还原为标准化前的结果"
    print("测试集预测房价结果：", '\n', y_predict)

    # 均方误差机制评估回归性能
    print("岭回归误差：", mean_squared_error(std_y.inverse_transform(y_test), y_predict))
    return None


if __name__ == "__main__":
    mylinear()

```

**运行结果**：

```python
[[17.8]
 [48.5]
 [19.1]
 [22.7]
 [10.4]
 [18.7]
 [38.7]
 [43.5]
 [27.1]
 [20.7]
 [21.2]
 [33.4]
 [50. ]
 [22.8]
 [18. ]
 [32. ]
 [50. ]
 [19.5]
 [19.6]
 [24.6]
 [15.6]
 [18.2]
 [14.9]
 [21.7]
 [24.7]
 [23.2]
 [ 7.4]
 [25. ]
 [20.5]
 [36.2]
 [37. ]
 [28.7]
 [30.3]
 [22.2]
 [11. ]
 [23. ]
 [23.2]
 [21.7]
 [50. ]
 [28.2]
 [16.7]
 [ 8.4]
 [23.2]
 [16.1]
 [19.5]
 [23.4]
 [20.4]
 [41.7]
 [12.5]
 [20.3]
 [25. ]
 [23. ]
 [19.7]
 [50. ]
 [30.7]
 [10.4]
 [34.6]
 [21.7]
 [15.2]
 [31.7]
 [ 5.6]
 [19.4]
 [27.9]
 [18.5]
 [20.6]
 [17.1]
 [20.4]
 [ 9.6]
 [21.8]
 [12.3]
 [21.4]
 [44. ]
 [20.9]
 [10.5]
 [14.5]
 [13.4]
 [31.2]
 [50. ]
 [34.9]
 [22.2]
 [27.9]
 [21.2]
 [23.8]
 [50. ]
 [32.7]
 [42.3]
 [23.7]
 [ 8.3]
 [18.9]
 [33.8]
 [32.4]
 [23.6]
 [21.6]
 [36.2]
 [23.7]
 [18.9]
 [41.3]
 [ 8.7]
 [24.1]
 [29.1]
 [13.9]
 [20. ]
 [10.8]
 [13.4]
 [13. ]
 [15.6]
 [27.5]
 [22.9]
 [42.8]
 [22. ]
 [12.7]
 [24.8]
 [31.5]
 [18.2]
 [14. ]
 [20.1]
 [12.6]
 [46. ]
 [21.9]
 [10.2]
 [28.4]
 [23.5]
 [21.4]
 [24.3]
 [20.3]
 [23.3]
 [24.1]]
训练得到的参数： 
 [[-0.09177998  0.13761083  0.01963181  0.05214068 -0.25201382  0.24538565
   0.03559008 -0.34515729  0.30906163 -0.26574487 -0.23110419  0.09883083
  -0.43051315]]
测试集预测房价结果： 
 [[18.41408768]
 [41.30740118]
 [16.83205162]
 [20.89616246]
 [ 7.37914938]
 [20.7898532 ]
 [34.50779589]
 [38.32819852]
 [27.07485764]
 [21.28556122]
 [21.14387092]
 [27.94891455]
 [39.34391441]
 [28.6835055 ]
 [18.73327059]
 [33.45396564]
 [32.92967027]
 [20.26279329]
 [22.74714736]
 [23.996809  ]
 [16.06236091]
 [19.46804643]
 [14.57308594]
 [20.89866583]
 [24.13346147]
 [21.84401573]
 [ 6.23889261]
 [27.28333289]
 [20.20321545]
 [27.83120275]
 [30.01810681]
 [25.14936306]
 [32.33553142]
 [24.09223884]
 [13.76739593]
 [19.92722635]
 [27.19648475]
 [23.07824021]
 [35.86594046]
 [32.56233748]
 [20.02877615]
 [ 4.62890039]
 [16.92600554]
 [18.11612606]
 [19.24422411]
 [24.05187757]
 [19.62864493]
 [36.50025458]
 [18.79373978]
 [23.77632268]
 [25.53108025]
 [28.93338172]
 [21.53799282]
 [41.6340855 ]
 [30.77429493]
 [14.41364517]
 [34.2706351 ]
 [21.95356685]
 [18.74519667]
 [32.46106072]
 [11.92697706]
 [23.34629068]
 [31.78135759]
 [14.07380638]
 [22.02906117]
 [19.13980703]
 [22.83003366]
 [14.03153923]
 [20.5944468 ]
 [13.26006834]
 [22.91230047]
 [37.08221408]
 [22.16378143]
 [ 7.15787887]
 [18.41078109]
 [12.879641  ]
 [27.98330442]
 [34.6251355 ]
 [29.64931719]
 [25.91938005]
 [20.25694624]
 [23.17918784]
 [26.40272649]
 [25.05976926]
 [29.71952312]
 [36.11519439]
 [26.98850085]
 [13.49881841]
 [24.00352245]
 [34.20933164]
 [34.8623073 ]
 [29.02105034]
 [25.58601271]
 [27.24844118]
 [11.04661055]
 [19.32926464]
 [32.81327941]
 [ 8.60031614]
 [29.63824317]
 [31.35075847]
 [13.93374765]
 [22.87509317]
 [11.46184417]
 [14.12675536]
 [16.75557715]
 [13.57072237]
 [24.11906924]
 [20.35717785]
 [28.07295036]
 [22.24814374]
 [12.42705058]
 [24.51497153]
 [31.88901967]
 [18.69559681]
 [13.45976141]
 [20.49902639]
 [17.77717386]
 [38.54689607]
 [16.06320323]
 [ 7.18195434]
 [28.24315485]
 [30.44075104]
 [24.79300014]
 [29.26304919]
 [19.86528724]
 [28.17997424]
 [20.40843184]]
岭回归误差： 27.529158664108838
```

# 岭回归较普通线性回归（正规方程）的优势

岭回归得到的回归系数更符合实际，更可靠。另外，能让估计参数的波动范围更小，变得更稳定。在存在病态数据偏多的研究中具有较大的实用价值。