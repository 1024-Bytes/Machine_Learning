# 数据特征预处理

前面已经学了文本类型的数据的特征抽取，下面是特征的处理

特征处理：通过特定的统计方法(数学方法)将数据（数值）转换成算法要求的数据。

数值型数据：标准缩放（归一化、标准化）,缺失值

类别型数据：one-hot编码

时间类型：时间的切分

特征预处理API：`sklearn.preprocessing`

## 归一化处理

通过对原始数据进行变换把数据映射到（默认为（0,1）之间)

公式：X'=(x-min)/(max-min)   X''=x'*(mx-mi)+mi

**注意**：是对每一列数据应用公式，max是一列的最大值，min是每一列的最小值，X''是最终结果，mx,mi分别为指定区间值，且默认值mx为1，mi为0。

API:`sklearn.preprocessing.MinMaxScaler`

语法：1.类：`MinMaxScaler(feature_range=(0,1))`每个特征值缩放到给定范围（默认是[0,1]）

​            2.转换方法：`MinMaxScaler.fit_transform(X)`

X：`numpy array`格式(数组形式)的数据`[n_samples,n_feartures]`       返回值：转换后形状相同的array

代码：

```python
from sklearn.preprocessing import MinMaxScaler
#导入特征预处理类
def mm():
    """
    归一化处理特征数据：
    ：return:None
    """
    mm = MinMaxScaler()
    # 实例化
    data=mm.fit_transform([[5,8,9],[6,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    #打印归一化处理后的数组
    return None
if __name__=="__main__":
       mm()
```

运行结果：

```python
[[0.         1.         1.        ]
 [0.33333333 0.75       0.        ]
 [1.         0.         0.5       ]]
```

当数据处理范围改成（2,3）时：

代码：

```python
from sklearn.preprocessing import MinMaxScaler
#导入归一化特征预处理类
def mm():
    """
    归一化处理特征数据：
    ：return:None
    """
    mm = MinMaxScaler(feature_range = (2,3))
    # 实例化，且数据处理范围在2到3之间
    data=mm.fit_transform([[5,8,9],[6,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    #打印归一化处理后的数组
    return None
if __name__=="__main__":
       mm()
```

运行结果：

```python
[[2.         3.         3.        ]
 [2.33333333 2.75       2.        ]
 [3.         2.         2.5       ]]

```

**注意：归一化处理特征数据代表这些特征同等重要**

**数据中异常点较多时**，数据极有可能通过影响某一列数据的最小值和最大值影响某一特征进行归一化处理时的准确性，所以这种方法**鲁棒性**较差，只适合**传统精确小数据**场景。

## 标准化

通过对原始数据进行变换把数据变换到均值为0，方差为1的范围内

公式(也是处理每一列的数据)：X'=(x-mean)/σ

mean是平均值，σ是标准

`var`是方差，`var=((x1-mean)²+(x2-mean)²+...)/n(每个特征样本数) , σ=var½` ,方差可以反映数据的稳定性

**如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小**

API:`sklearn.peprocessing.StandardScaler`

语法：1.转换数据：`StandardScaler.fit_transform(X)`

X:`numpy array`格式数据，返回值：转换后形状相同的array

2.返回原始数据中每列特征的平均值：`StandardScaler.mean_`

3.返回原始数据每列特征的方差：`StandardScaler.std_`

代码：

```python
from sklearn.preprocessing import StandardScaler
#导入标准化特征预处理类
def standard():
    """
    标准化处理特征数据：
    ：return:None
    """
    bz = StandardScaler()
    # 实例化
    data=bz.fit_transform([[5,8,9],[6,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    #打印标准化化处理后的数组
    return None
if __name__=="__main__":
       standard()
```

运行结果：

```python
[[-1.06904497  0.98058068  1.22474487]
 [-0.26726124  0.39223227 -1.22474487]
 [ 1.33630621 -1.37281295  0.        ]]
```

标准化较归一化常用，在已有样本足够多的情况下比较稳定，适合现代嘈杂的大数据场景