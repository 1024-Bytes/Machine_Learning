# 数据特征预处理

前面已经学了文本类型的数据的特征抽取，下面是特征的处理

特征处理：通过特定的统计方法(数学方法)将数据（数值）转换成算法要求的数据。

数值型数据：标准缩放（归一化、标准化）,缺失值

类别型数据：one-hot编码

时间类型：时间的切分

特征预处理API：`sklearn.preprocessing`

## 归一化处理

通过对原始数据进行变换把数据映射到（默认为（0,1）之间)

公式：X'=(x-min)/(max-min)   X''=x'*(mx-mi)+mi

**注意**：是对每一列数据应用公式，max是一列的最大值，min是每一列的最小值，X''是最终结果，mx,mi分别为指定区间值，且默认值mx为1，mi为0。

API:`sklearn.preprocessing.MinMaxScaler`

语法：1.类：`MinMaxScaler(feature_range=(0,1))`每个特征值缩放到给定范围（默认是[0,1]）

​            2.转换方法：`MinMaxScaler.fit_transform(X)`

X：`numpy array`格式(数组形式)的数据`[n_samples,n_feartures]`       返回值：转换后形状相同的array

代码：

```python
from sklearn.preprocessing import MinMaxScaler
#导入特征预处理类
def mm():
    """
    归一化处理特征数据：
    ：return:None
    """
    mm = MinMaxScaler()
    # 实例化
    data=mm.fit_transform([[5,8,9],[6,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    #打印归一化处理后的数组
    return None
if __name__=="__main__":
       mm()
```

运行结果：

```python
[[0.         1.         1.        ]
 [0.33333333 0.75       0.        ]
 [1.         0.         0.5       ]]
```

当数据处理范围改成（2,3）时：

代码：

```python
from sklearn.preprocessing import MinMaxScaler
#导入归一化特征预处理类
def mm():
    """
    归一化处理特征数据：
    ：return:None
    """
    mm = MinMaxScaler(feature_range = (2,3))
    # 实例化，且数据处理范围在2到3之间
    data=mm.fit_transform([[5,8,9],[6,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    #打印归一化处理后的数组
    return None
if __name__=="__main__":
       mm()
```

运行结果：

```python
[[2.         3.         3.        ]
 [2.33333333 2.75       2.        ]
 [3.         2.         2.5       ]]

```

**注意：归一化处理特征数据代表这些特征同等重要**

**数据中异常点较多时**，数据极有可能通过影响某一列数据的最小值和最大值影响某一特征进行归一化处理时的准确性，所以这种方法**鲁棒性**较差，只适合**传统精确小数据**场景。

## 标准化

通过对原始数据进行变换把数据变换到均值为0，方差为1的范围内

公式(也是处理每一列的数据)：X'=(x-mean)/σ

mean是平均值，σ是标准

`var`是方差，`var=((x1-mean)²+(x2-mean)²+...)/n(每个特征样本数) , σ=var½` ,方差可以反映数据的稳定性

**如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小**

API:`sklearn.peprocessing.StandardScaler`

语法：1.转换数据：`StandardScaler.fit_transform(X)`

X:`numpy array`格式数据，返回值：转换后形状相同的array

2.返回原始数据中每列特征的平均值：`StandardScaler.mean_`

3.返回原始数据每列特征的方差：`StandardScaler.std_`

代码：

```python
from sklearn.preprocessing import StandardScaler
#导入标准化特征预处理类
def standard():
    """
    标准化处理特征数据：
    ：return:None
    """
    bz = StandardScaler()
    # 实例化
    data=bz.fit_transform([[5,8,9],[6,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    #打印标准化化处理后的数组
    return None
if __name__=="__main__":
       standard()
```

运行结果：

```python
[[-1.06904497  0.98058068  1.22474487]
 [-0.26726124  0.39223227 -1.22474487]
 [ 1.33630621 -1.37281295  0.        ]]
```

标准化较归一化常用，在已有样本足够多的情况下比较稳定，适合现代嘈杂的大数据场景

# 缺失值处理

数值型数据的处理除了之前的归一化和标准化处理外，还有缺失值的处理

缺失值处理有两种方法，插补和删除，但一般插补比较常用

| 插补 | 如果每列或者行数据缺失值达到一定的比例，建议放弃整行或整列   |
| ---- | ------------------------------------------------------------ |
| 删除 | 可以通过缺失值每行或者每列的平均值、中位数来填充，当然按列会较准确，也就是特征值 |

`sklearn`中缺失值API：`sklearn.processing.Imputer`

**注**：缺失值处理对象也可以需要替换的值

语法：

1.缺失值插补：`Imputer(missing_values='NaN',strategy='mean',axis=0)`

missing_values为缺失值（nan或Nan)，strategy为填补策略（即填补值类别,像平均值、中位数等），axis指定位置

2.`Imputer.fit_transform(X)`

X:`numpy array`格式的数据，返回值是转换后形状相同的array

同pandas（pandas中有`dropna`和`fillna`方法处理缺失值）一样，数据中缺失值必须为`np.nan`类型（缺失值处理前可以用replace()函数将缺失值转换成`np.nan`类型）

代码：

```python
import numpy as np
from sklearn.preprocessing import Imputer
#导入缺失值填补包
def complete():
    """
    特征数据填补缺失值：
    ：return:None
    """
    qsz = Imputer(missing_values='NaN',strategy='mean',axis=0)
    # 实例化
    data=qsz.fit_transform([[5,8,9],[np.nan,7,3],[8,4,6]])
    # 传入数组数据，调用fit_transform处理实例化后的数组
    print(data)
    # 打印填补缺失值后的数组
    return None
if __name__=="__main__":
       complete()
```

运行结果：

```python
[[5.  8.  9. ]
 [6.5 7.  3. ]
 [8.  4.  6. ]]
```

当axis=1时，将按行填补

关于`np.nan`：1.numpy的数组中可以使用`np.nan`来代替缺失值，属于float类型

2.如果是文件中的一些缺失值，可以替换成nan,通过`np.array`转化成float型的数组即可

