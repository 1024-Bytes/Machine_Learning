# 模型选择与调优

## 1.交叉验证

目的：为了让评估模型更加准确可信

过程：将拿到的训练数据，分为训练和验证集。以下图为例，将数据分成5份，其中一份作为验证集。然后经过5次(组)的测试，每次都更换不同的验证集。即得到5组的模型的结果，取平均值作为最终结果。又称5折交叉验证。

|      |    全部    |   数据中   |   划分给   |   训练集   |   的数据   |
| :--: | :--------: | :--------: | :--------: | :--------: | :--------: |
| 图一 | **验证集** |   训练集   |   训练集   |   训练集   |   训练集   |
| 图二 |   训练集   | **验证集** |   训练集   |   训练集   |   训练集   |
| 图三 |   训练集   |   训练集   | **验证集** |   训练集   |   训练集   |
| 图四 |   训练集   |   训练集   |   训练集   | **验证集** |   训练集   |
| 图五 |   训练集   |   训练集   |   训练集   |   训练集   | **验证集** |



## 2.超参数搜索—网格搜索

目的：用于调参数，例如：K-近邻算法的K值

过程：通常情况下，有许多参数是需要手动指定的(如K-近邻算法中的K值)，这种叫超参数。但是手动过程繁杂，所以需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。

| K值  | K=3   | K=5   | K=7   |
| ---- | ----- | ----- | ----- |
| 模型 | 模型1 | 模型2 | 模型3 |

常用十折交叉验证

### 超参数搜索—网格搜索`API`

`sklearn.model_selection。GridSearchCV`

**语法**：

`sklearn.model_GridSearchCV(estimator,param_grid=None,cv=None)`

对估计器的指定参数进行详尽搜索

`estimator`:估计器对象

`param_grid`:估计器参数`(dict){"n_neighbors":[1,3,5]}`

`cv`:指定几折交叉验证

`fit`:输入训练数据

`score`:准确率

结果分析：

`best_score_`:在交叉验证中验证的最好结果

`best_estimator_`:最好的参数模型

`cv_results_`:每次交叉验证后的验证集准确率结果和训练集准确率结果

# 网格搜索应用举例

**代码**：

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.preprocessing import StandardScaler
import pandas as pd
def knn_cls():
    """
    K近邻预测用户签到位置
    :return: None
    """
    # 读取数据
    data=pd.read_csv('./datasets/train.csv')
    # 处理数据
    # 1.筛选数据以缩小数据范围
    data = data.query('x>1.0 & x<1.25 & y>2.5 & y<2.75')
    # 2.处理时间数据
    time_value = pd.to_datetime(data['time'], unit='s')
    # 将日期格式转换成字典格式
    time_value = pd.DatetimeIndex(time_value)
    # 构造一些特征
    data['day'] = time_value.day
    data['hour'] = time_value.hour
    data['weekday'] = time_value.weekday
    # 把时间戳特征删除(1表示列，0表示行)
    data.drop(['time'],axis=1)
    # 3.把签到数量少于n个目标位置删除
    # 按place_id进行分组
    place_count = data.groupby('place_id').count()
    # 删除次数少于n的位置并重置索引
    tf = place_count[place_count.row_id > 3].reset_index()
    # 筛选data中符合条件的样本
    data = data[data['place_id'].isin(tf.place_id)]
    # 取出数据当中的特征值和目标值
    y = data['place_id']
    x = data.drop(['place_id'],axis=1).drop(['row_id'],axis=1)
    # 进行数据集的分割
    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25)
    # 特征工程(标准化）
    std = StandardScaler()
    # 对训练集和特征集进行标准化处理
    x_train = std.fit_transform(x_train)
    x_test = std.fit_transform(x_test)
    # 进行算法流程
    # 1.实例化
    knn = KNeighborsClassifier()
    # 2.进行网格搜索
    # 构造超参数组合
    param = {"n_neighbors": [3, 5, 7, 10]}
    # 实例化网格搜索对象
    gc = GridSearchCV(knn, param_grid=param, cv=10)
    # 传入训练集数据
    gc.fit(x_train, y_train)
    # 输出预测网格搜索结果
    print("在测试集上准确率：", '\n',gc.score(x_test, y_test))
    print("在交叉验证中最好的结果：", '\n', gc.best_score_)
    print("最好的参数模型：", '\n', gc.best_estimator_)
    print("每次交叉验证的结果：", '\n', gc.cv_results_)
    # 3.传入训练数据
    knn.fit(x_train, y_train)
    # 4.传入测试集进行预测
    y_predict = knn.predict(x_test)
    # 5.打印预测值
    print("预测的目标签到位置:", '\n', y_predict)
    # 6.打印准确率
    print("预测的准确率:", '\n', knn.score(x_test, y_test))
    return None


if __name__ == '__main__':
    knn_cls()
```

**运行结果**：

```python
在测试集上准确率： 
 0.48392434988179667
在交叉验证中最好的结果： 
 0.47209962168978564
最好的参数模型： 
 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,
                     weights='uniform')
每次交叉验证的结果： 
 {'mean_fit_time': array([0.01714537, 0.009711  , 0.01003432, 0.01173937]), 'std_fit_time': array([0.02219247, 0.00104964, 0.00085219, 0.0020524 ]), 'mean_score_time': array([0.05306628, 0.05547619, 0.05912735, 0.0811981 ]), 'std_score_time': array([0.00553764, 0.00540431, 0.0041918 , 0.01401058]), 'param_n_neighbors': masked_array(data=[3, 5, 7, 10],
             mask=[False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}, {'n_neighbors': 10}], 'split0_test_score': array([0.42010123, 0.43528561, 0.43239335, 0.42588576]), 'split1_test_score': array([0.41788856, 0.45674487, 0.45234604, 0.44721408]), 'split2_test_score': array([0.43070045, 0.44560358, 0.44709389, 0.45454545]), 'split3_test_score': array([0.42520881, 0.43204252, 0.44343204, 0.45102506]), 'split4_test_score': array([0.46540881, 0.47955975, 0.47798742, 0.47955975]), 'split5_test_score': array([0.46618357, 0.49194847, 0.49275362, 0.49194847]), 'split6_test_score': array([0.4627964 , 0.47587899, 0.4840556 , 0.47506132]), 'split7_test_score': array([0.48621554, 0.48538012, 0.49456976, 0.4845447 ]), 'split8_test_score': array([0.46830093, 0.50633981, 0.50549451, 0.50549451]), 'split9_test_score': array([0.47896996, 0.50643777, 0.5055794 , 0.51072961]), 'mean_test_score': array([0.45081967, 0.47012926, 0.47209962, 0.47115385]), 'std_test_score': array([0.0246588 , 0.02626276, 0.02605347, 0.02603404]), 'rank_test_score': array([4, 3, 1, 2])}
预测的目标签到位置: 
 [1097200869 3741484405 3992589015 ... 2946102544 5270522918 6424972551]
预测的准确率: 
 0.4867612293144208
```

